# LatticeDB: Deterministic Storage for Time-Travel Simulations

**Version:** 1.0.0
**Status:** In Development
**Last Updated:** 2026-01-06

---

## Why LatticeDB?

Traditional databases don't understand simulation time. LatticeDB was built to solve specific problems that arise when you need deterministic, time-aware storage for simulations:

### The Problems

**1. No Simulation Time Awareness**
- PostgreSQL, MongoDB, and others track wall-clock time (`DateTime.Now`)
- They don't understand ticks - discrete simulation time units
- Querying "what was the state at tick 5000?" requires custom temporal extensions
- Time-travel queries are bolted on, not built in

**2. No Built-In Time-Travel**
- Historical state requires custom versioning tables
- Reconstructing past states means replaying change logs
- Branching timelines ("what if" scenarios) requires application-level complexity
- No native snapshot/restore primitives

**3. CRDT Support Missing**
- Conflict-free data types (counters, sets, maps) require custom layers
- Multi-master replication needs manual conflict resolution
- No guarantees about merge convergence

**4. Non-Deterministic Query Ordering**
- `Dictionary<K,V>` iteration order varies between runs
- `HashSet<T>` enumeration is non-deterministic
- Index scan order can differ based on implementation details
- This breaks simulation determinism

**5. Schema Enforcement Gaps**
- MongoDB allows arbitrary document shapes
- PostgreSQL requires migrations for schema changes
- No compile-time guarantee that code matches database schema

---

## How Lattice Solves It

### Core Principles

1. **Tick-Aware by Default** - Every query understands simulation time
2. **Chronicle Built-In** - Time-travel is a first-class feature, not an extension
3. **Deterministic Ordering** - Query results are stable across runs
4. **Schema Authority** - Axion schemas define storage structures
5. **CRDT Native** - Conflict-free data types for distributed consistency

### Technical Approach

#### Tick-Aware Storage
```csharp
// Storage engine tracks tick metadata
public interface IStorageEngine
{
    void Put(ReadOnlySpan<byte> key, ReadOnlySpan<byte> value);
    bool TryGet(ReadOnlySpan<byte> key, out byte[] value);
    IEnumerable<KeyValuePair<byte[], byte[]>> Scan(ReadOnlySpan<byte> prefix);
}

// Chronicle wraps storage with temporal versioning
public sealed class ChronicleEngine
{
    Snapshot CreateSnapshot(ulong tick, byte[] stateData, ulong stateHash);
    TravelResult TravelTo(ulong targetTick);
    BranchResult Branch(ulong snapshotId, BranchOptions options);
}
```

#### Deterministic Collections
All Lattice storage operations return results in sorted order:
- Keys are ordered lexicographically
- Scan operations return deterministic sequences
- CRDT merge operations preserve commutativity

#### Schema-Driven Types
```csharp
// Axion schema defines structure
// schemas/lattice/storage.axion
entity Transaction {
    @key id: uuid;
    state: TransactionState;
    start_tick: int64;
    commit_tick: int64?;
}

// Generated code implements storage interface
// ILatticeEntity<T> for ORM integration
public interface ILatticeEntity<TSelf> where TSelf : struct, ILatticeEntity<TSelf>
{
    uint Id { get; set; }
    void Serialize(ref BitWriter writer);
    static abstract TSelf Deserialize(ref BitReader reader);
}
```

---

## What Lattice Provides

### Architecture Overview

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Application Layer                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Lattice.ORM      â”‚  Lattice.QL       â”‚  Lattice.Client â”‚
â”‚  (Active Record)  â”‚  (Query Language) â”‚  (Network API)  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          Lattice.Chronicle (Time-Travel Layer)          â”‚
â”‚  - Snapshots      - Branching       - Version Tracking  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚             Lattice.DB (Storage Engine Layer)           â”‚
â”‚  - Memory         - File            - Binary Pages      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚          Lattice.CRDT (Conflict-Free Data Types)        â”‚
â”‚  - Counters       - Sets            - Maps              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚       Lattice.Replication (Multi-Node Sync Layer)       â”‚
â”‚  - Sync Protocol  - Conflict Resolution - Delta Logs    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Component Status

| Component | Status | Description |
|-----------|--------|-------------|
| **Lattice.DB** | âœ… Implemented | Core key-value storage engine |
| **Lattice.Chronicle** | âœ… Implemented | Time-travel snapshots and branching |
| **Lattice.ORM** | ðŸš§ In Progress | Object-relational mapping layer |
| **Lattice.QL** | ðŸš§ In Progress | Query language parser (GraphQL-like) |
| **Lattice.CRDT** | âœ… Implemented | GCounter, PNCounter, OR-Set, G-Set, 2P-Set |
| **Lattice.Search** | ðŸ“‹ Planned | Full-text search indexing |
| **Lattice.Replication** | ðŸš§ In Progress | Multi-node synchronization |
| **Lattice.Server** | ðŸš§ In Progress | HTTP/gRPC/WebSocket transports |
| **Lattice.Client** | ðŸš§ In Progress | Client library for remote access |
| **Lattice.Crypto** | ðŸš§ In Progress | Capability-based access control |
| **Lattice.Optimization** | ðŸš§ In Progress | Query planner and batch executor |

---

## Lattice.DB: Core Storage

### Storage Engines

LatticeDB supports multiple backend engines:

```csharp
public enum StorageEngine
{
    Lmdb = 0,      // Lightning Memory-Mapped Database (default)
    Sqlite = 1,    // SQLite for compatibility
    RocksDb = 2,   // RocksDB for high-throughput
    Memory = 3     // In-memory for testing
}
```

### Key-Value Operations

```csharp
// Open storage
var engine = new MemoryStorageEngine();
engine.Open(":memory:");

// Store data
engine.Put("user:123"u8, userData);

// Retrieve data
if (engine.TryGet("user:123"u8, out var data))
{
    // Process data
}

// Range scan (deterministic order)
foreach (var kvp in engine.Scan("user:"u8))
{
    Console.WriteLine($"Key: {Encoding.UTF8.GetString(kvp.Key)}");
}

// Count keys with prefix
int userCount = engine.Count("user:"u8);

// Delete range
int deleted = engine.DeleteRange("user:"u8);
```

### Transaction Support

```csharp
// Use transactional storage for atomic operations
if (engine is ITransactionalStorage txStorage)
{
    using var tx = txStorage.BeginTransaction();
    try
    {
        tx.Put("balance:123"u8, newBalance);
        tx.Put("history:123:5000"u8, historyEntry);
        tx.Commit();
    }
    catch
    {
        tx.Rollback();
        throw;
    }
}
```

### Configuration

```csharp
config StorageConfig {
    engine: StorageEngine = Lmdb;
    max_size_bytes: int64 = 0;           // 0 = unlimited
    page_size: int32 = 4096;             // 4KB pages
    mmap: bool = true;                   // Memory-mapped I/O
    sync_mode: SyncMode = Normal;        // Write synchronization
    wal_enabled: bool = true;            // Write-ahead logging
}
```

---

## Lattice.Chronicle: Time-Travel Engine

Chronicle enables snapshot-based time travel and timeline branching.

### Creating Snapshots

```csharp
var chronicle = new ChronicleEngine(storageEngine);
chronicle.EnsureMainTimeline();

// Capture state at current tick
var snapshot = chronicle.CreateSnapshot(
    tick: 5000,
    stateData: SerializeGameState(),
    stateHash: ComputeStateHash(),
    options: new SnapshotOptions
    {
        Label = "Before boss fight",
        Compress = true
    }
);

Console.WriteLine($"Snapshot {snapshot.Id} at tick {snapshot.Tick}");
Console.WriteLine($"Size: {snapshot.Data.Length} bytes (compressed from {snapshot.UncompressedSize})");
```

### Time-Travel Queries

```csharp
// Travel to a specific tick
var result = chronicle.TravelTo(targetTick: 3500);

if (result.Success)
{
    Console.WriteLine($"Found snapshot at tick {result.Snapshot.Tick}");
    Console.WriteLine($"Need to replay {result.TicksReplayed} ticks");
    Console.WriteLine($"Retrieved in {result.ElapsedMicroseconds} Âµs");

    // Restore state
    RestoreGameState(result.StateData);
}
```

### Timeline Branching

```csharp
// Branch from a snapshot to explore alternate outcomes
var branchResult = chronicle.Branch(
    snapshotId: snapshot.Id,
    options: new BranchOptions
    {
        Name = "What if player chose door B?",
        Description = "Alternate timeline where player made different choice",
        SwitchToNewTimeline = true
    }
);

if (branchResult.Success)
{
    Console.WriteLine($"Created timeline {branchResult.Timeline.Id}");
    Console.WriteLine($"Branched from tick {branchResult.BranchPoint.Tick}");

    // Continue simulation in alternate timeline
    // Original timeline remains unchanged
}
```

### Timeline Management

```csharp
// List all timelines
foreach (var timeline in chronicle.Timelines)
{
    Console.WriteLine($"Timeline {timeline.Id}: {timeline.Name}");
    Console.WriteLine($"  Created at tick: {timeline.CreatedAtTick}");
    Console.WriteLine($"  Current tick: {timeline.CurrentTick}");
    Console.WriteLine($"  Active: {timeline.IsActive}");
}

// Switch between timelines
chronicle.SwitchTimeline(timelineId: 2);

// Compare states across timelines
var comparison = chronicle.Compare(
    timelineA: 1,
    timelineB: 2,
    tick: 5000
);

Console.WriteLine($"Timeline 1 hash: {comparison.StateHashA:X16}");
Console.WriteLine($"Timeline 2 hash: {comparison.StateHashB:X16}");
Console.WriteLine($"Diverged: {comparison.StateHashA != comparison.StateHashB}");
```

### Snapshot Verification

```csharp
// Verify snapshot integrity
bool valid = chronicle.VerifySnapshot(
    snapshotId: snapshot.Id,
    hashFunction: data => ComputeStateHash(data)
);

if (!valid)
{
    Console.WriteLine("WARNING: Snapshot integrity check failed!");
}
```

### Chronicle Statistics

```csharp
var stats = chronicle.GetStats();
Console.WriteLine($"Timelines: {stats.TimelineCount}");
Console.WriteLine($"Snapshots: {stats.SnapshotCount}");
Console.WriteLine($"Total data: {stats.TotalDataBytes / 1024} KB");
Console.WriteLine($"Uncompressed: {stats.TotalUncompressedBytes / 1024} KB");
Console.WriteLine($"Compression ratio: {stats.CompressionRatio:P1}");
```

---

## Lattice.QL: Query Language

Lattice Query Language (LatticeQL) is a GraphQL-inspired language with temporal extensions.

### Query Syntax

```graphql
# Basic query
query GetPlayer {
    player(id: "123") {
        name
        score
        level
    }
}

# Time-travel query
query GetPlayerHistory {
    player(id: "123") @at(tick: 5000) {
        name
        score
    }
}

# Range query
query HighScorers {
    players(where: { score_gt: 1000 }, orderBy: score_DESC) {
        name
        score
    }
}

# Temporal range
query PlayerScoreHistory {
    player(id: "123") @between(start: 1000, end: 5000) {
        tick
        score
    }
}
```

### Query Execution (In Progress)

```csharp
var parser = QueryParser.Parse(@"
    query GetPlayer {
        player(id: ""123"") {
            name
            score
        }
    }
");

if (!parser.HasErrors)
{
    var document = parser.Document;
    // Execute query (executor not yet implemented)
}
```

---

## Lattice.CRDT: Conflict-Free Data Types

CRDTs enable distributed state that converges without coordination.

### Counters

#### GCounter (Grow-Only Counter)

```csharp
// Create counter for this node
var counter = new GCounter(nodeId: "node-1");

// Increment locally
counter.Increment(10);
counter.Increment(5);

Console.WriteLine($"Value: {counter.Value}"); // 15

// Merge from another node
var otherCounter = new GCounter(nodeId: "node-2");
otherCounter.Increment(20);

counter.Merge(otherCounter);
Console.WriteLine($"Merged value: {counter.Value}"); // 35

// Serialize for network transmission
byte[] bytes = counter.ToBytes();
var restored = GCounter.FromBytes(bytes, "node-1");
```

#### PNCounter (Positive-Negative Counter)

```csharp
// Counter that supports both increment and decrement
var counter = new PnCounter(nodeId: "node-1");

counter.Increment(100);
counter.Decrement(30);

Console.WriteLine($"Value: {counter.Value}"); // 70
Console.WriteLine($"Total increments: {counter.TotalIncrements}"); // 100
Console.WriteLine($"Total decrements: {counter.TotalDecrements}"); // 30

// Merge from another node
var other = new PnCounter(nodeId: "node-2");
other.Increment(50);
counter.Merge(other);

Console.WriteLine($"Merged: {counter.Value}"); // 120
```

#### BoundedCounter (Lower-Bounded Counter)

```csharp
// Counter that cannot go below zero (useful for inventory)
var inventory = new BoundedCounter(nodeId: "node-1", lowerBound: 0);

inventory.Increment(100);

// Try to decrement
if (inventory.TryDecrement(30))
{
    Console.WriteLine("Decremented successfully");
}

// This would fail (returns false)
bool success = inventory.TryDecrement(200);
```

### Sets

#### GSet (Grow-Only Set)

```csharp
// Set that only supports additions
var achievements = new GSet<string>();

achievements.Add("First Victory");
achievements.Add("Level 10");
achievements.Add("Perfect Score");

Console.WriteLine($"Count: {achievements.Count}"); // 3
Console.WriteLine($"Has 'Level 10': {achievements.Contains("Level 10")}"); // true

// Merge from another node
var otherAchievements = new GSet<string>();
otherAchievements.Add("Speed Run");

achievements.Merge(otherAchievements);
Console.WriteLine($"Merged count: {achievements.Count}"); // 4
```

#### ORSet (Observed-Remove Set / Add-Wins Set)

```csharp
// Set supporting both add and remove
// Uses Hybrid Logical Clock for causality tracking
var clock = new HybridLogicalClock("node-1");
var friends = new OrSet<string>("node-1", clock);

friends.Add("Alice");
friends.Add("Bob");
friends.Add("Charlie");

Console.WriteLine($"Friends: {friends.Count}"); // 3

// Remove a friend
friends.Remove("Bob");
Console.WriteLine($"Friends: {friends.Count}"); // 2

// Merge from another node
var otherFriends = new OrSet<string>("node-2", new HybridLogicalClock("node-2"));
otherFriends.Add("Diana");

friends.Merge(otherFriends);
Console.WriteLine($"Merged friends: {friends.Count}"); // 3

// Tombstone garbage collection (remove old deletion markers)
var cutoff = clock.Now();
int removed = friends.CollectGarbage(cutoff);
```

#### TwoPhaseSet (2P-Set)

```csharp
// Set where removal is permanent (element can never be re-added)
var permissions = new TwoPhaseSet<string>();

permissions.Add("read");
permissions.Add("write");
permissions.Add("execute");

// Revoke permission (permanent)
permissions.Remove("execute");

// Try to re-add (throws exception)
try
{
    permissions.Add("execute");
}
catch (InvalidOperationException)
{
    Console.WriteLine("Cannot re-add removed permission");
}

// Safe version
bool added = permissions.TryAdd("execute"); // Returns false
```

### CRDT Characteristics

All Lattice CRDTs satisfy:

1. **Convergence**: All replicas that receive the same updates will have identical state
2. **Commutativity**: Updates can be applied in any order
3. **Idempotence**: Applying the same update twice has no additional effect
4. **Associativity**: Merge(A, Merge(B, C)) = Merge(Merge(A, B), C)

### Serialization

```csharp
// All CRDTs implement ISerializableCrdt
ISerializableCrdt crdt = counter;
byte[] serialized = crdt.ToBytes();

// Transmit over network, store to disk, etc.

// Deserialize
var restored = GCounter.FromBytes(serialized, "node-1");
```

---

## Lattice.Replication: Multi-Node Sync

**Status:** In Progress

Enables synchronization across multiple Lattice instances.

```csharp
// Create replication node
var node = new ReplicationNode(
    nodeId: "node-1",
    storage: storageEngine
);

// Connect to peer
node.ConnectToPeer("node-2", "tcp://192.168.1.100:5000");

// Sync protocol handles:
// - Delta transmission (only changes since last sync)
// - Conflict resolution (using CRDT semantics)
// - Vector clocks (for causality tracking)
// - Compression (LZ4 for efficient network usage)
```

---

## Lattice.ORM: Object-Relational Mapping

**Status:** In Progress

Provides Active Record pattern for entities.

```csharp
// Define entity via Axion schema
// schemas/game/inventory.axion
entity InventoryItem {
    @key id: uint;
    name: string;
    quantity: int32;
    category: ItemCategory;
}

// Generated code implements ILatticeEntity<T>
// Use Active Record methods:

var item = new InventoryItem
{
    Name = "Health Potion",
    Quantity = 10,
    Category = ItemCategory.Consumable
};

item.Save(); // Persists to storage

// Find by ID
var loaded = InventoryItem.Find(item.Id);

// Update
loaded.Quantity += 5;
loaded.Save();

// Delete
loaded.Delete();

// Query
var consumables = InventoryItem.Where(i => i.Category == ItemCategory.Consumable);
```

---

## Advantages

### 1. Time-Travel Built-In

No need for custom temporal tables or application-level versioning:

```csharp
// Traditional DB
var state = await db.ExecuteQuery(
    "SELECT * FROM game_state WHERE tick <= @tick ORDER BY tick DESC LIMIT 1",
    new { tick = 5000 }
);

// LatticeDB
var state = chronicle.TravelTo(5000);
```

### 2. CRDT for Distributed Consistency

Built-in conflict-free data types eliminate coordination overhead:

```csharp
// Traditional DB: Manual conflict resolution
try
{
    var current = await db.GetCounter("player:score");
    await db.UpdateCounter("player:score", current + 10);
}
catch (ConcurrencyException)
{
    // Retry or merge manually
}

// LatticeDB: Automatic convergence
counter.Increment(10);
counter.Merge(otherNodeCounter); // Always converges
```

### 3. Tick-Aware Queries

First-class support for simulation time:

```graphql
# Query state at specific tick
query {
    player(id: "123") @at(tick: 5000) {
        position { x, y }
        health
    }
}

# Query changes over time range
query {
    player(id: "123") @between(start: 1000, end: 2000) {
        events {
            tick
            type
        }
    }
}
```

### 4. Schema-Driven Development

Axion schemas ensure code and storage are always in sync:

- Compile-time type safety
- No runtime schema mismatches
- Automatic serialization code generation
- Schema versioning and migration support

### 5. Deterministic Guarantees

All operations produce stable, reproducible results:

- Key iteration is lexicographically ordered
- CRDT merges are commutative and associative
- Query results are deterministic across runs
- No hidden state or ambient time

---

## Disadvantages

### 1. Learning Curve

New query language and concepts:

- Developers must learn LatticeQL syntax
- CRDT semantics differ from traditional locks
- Tick-based time model requires mindset shift
- Chronicle timeline management adds complexity

### 2. More Complex Than Key-Value

Not as simple as Redis or basic key-value stores:

- Chronicle adds versioning overhead
- CRDT metadata increases storage size
- Transaction isolation levels to understand
- Multiple storage engines to choose from

### 3. Storage Overhead for History

Time-travel requires keeping historical state:

- Snapshots consume disk space
- Delta compression helps but adds CPU cost
- Retention policies need careful tuning
- Garbage collection necessary for long-running systems

### 4. In-Progress Features

Some components are not yet complete:

- Lattice.QL query executor (parser done, executor in progress)
- Lattice.Search full-text indexing (planned)
- Lattice.Optimization query planner (in progress)
- Network replication protocol (in progress)

### 5. Specialized Use Case

Not a general-purpose database:

- Optimized for simulation/gaming workloads
- May be overkill for simple CRUD applications
- Tick-based model not suitable for all domains
- Chronicle overhead unnecessary if time-travel not needed

---

## Comparison with Other Databases

### vs PostgreSQL with Temporal Extensions

| Feature | PostgreSQL + Extension | LatticeDB |
|---------|----------------------|-----------|
| Time-travel | Add-on (pg_temporal) | Built-in (Chronicle) |
| CRDT support | Manual implementation | Native (Lattice.CRDT) |
| Determinism | Query order may vary | Guaranteed deterministic |
| Tick awareness | Application layer | First-class concept |
| Schema sync | Manual migrations | Axion code generation |
| Branching | Not supported | Native timeline branching |

**Winner**: LatticeDB for simulation workloads requiring determinism and time-travel

### vs MongoDB

| Feature | MongoDB | LatticeDB |
|---------|---------|-----------|
| Schema | Flexible (pro/con) | Enforced via Axion |
| Versioning | Application-level | Built-in Chronicle |
| Determinism | Document order varies | Guaranteed stable |
| CRDT | Not supported | Native types |
| Query language | MQL (JavaScript-like) | LatticeQL (GraphQL-like) |
| Replication | Built-in (replica sets) | In progress |

**Winner**: MongoDB for general web apps, LatticeDB for deterministic simulations

### vs FoundationDB

| Feature | FoundationDB | LatticeDB |
|---------|--------------|-----------|
| Transactions | ACID, serializable | ACID with tick metadata |
| Abstractions | Low-level key-value | Higher-level (ORM, QL) |
| Time-travel | Not built-in | Native Chronicle |
| CRDT | Not supported | Native types |
| Determinism | Guaranteed | Guaranteed |
| Complexity | High (bare metal) | Medium (more abstractions) |

**Winner**: FoundationDB for maximum control, LatticeDB for faster development

### vs Redis

| Feature | Redis | LatticeDB |
|---------|-------|-----------|
| Persistence | Optional (RDB/AOF) | Primary focus |
| Data types | String, Hash, Set, etc. | Axion-defined structs + CRDTs |
| Time-travel | Not supported | Native Chronicle |
| Determinism | Not guaranteed | Guaranteed |
| Query language | Commands | LatticeQL (planned) |
| Use case | Cache/pub-sub | Persistent simulation state |

**Winner**: Redis for caching, LatticeDB for persistent deterministic state

---

## Performance Targets

These are design goals; actual performance depends on workload:

### Write Latency

| Operation | Target | Notes |
|-----------|--------|-------|
| Single Put | <1ms | Local storage, no sync |
| Transactional Put | <5ms | With durability guarantees |
| Snapshot Creation | <10ms | For typical game state (1-10 MB) |
| CRDT Merge | <1ms | Per operation, amortized |

### Read Latency

| Operation | Target | Notes |
|-----------|--------|-------|
| Single Get | <0.1ms | Cached in memory |
| Range Scan (1000 items) | <5ms | Sequential read |
| Time-Travel Query | <10ms | Recent history (last 1000 ticks) |
| Snapshot Restore | <50ms | Decompression + load |

### Throughput

| Workload | Target | Notes |
|----------|--------|-------|
| Writes/sec | 100K+ | Batch operations, memory engine |
| Reads/sec | 500K+ | Hot data cached |
| Snapshots/sec | 100 | Concurrent snapshot creation |

### Storage

| Metric | Target | Notes |
|--------|--------|-------|
| Compression ratio | 2-4x | LZ4 compression on snapshots |
| Overhead | 10-20% | Version metadata, indexes |
| Compaction | <1% | Amortized write amplification |

---

## Usage Recommendations

### When to Use LatticeDB

âœ… **Use LatticeDB if you need:**
- Deterministic simulation state
- Time-travel debugging ("go back to tick 5000")
- Timeline branching ("what if" scenarios)
- Distributed state with CRDTs
- Tick-based time model
- Schema-enforced types

### When NOT to Use LatticeDB

âŒ **Don't use LatticeDB if you need:**
- Simple key-value caching (use Redis)
- General CRUD web app (use PostgreSQL/MongoDB)
- Maximum raw throughput (use FoundationDB)
- No schema enforcement (use MongoDB)
- Real-time analytics (use ClickHouse)
- Graph queries (use Neo4j)

### Migration Path

If you're considering migrating to LatticeDB:

1. **Prototype Phase**: Use Lattice.DB with in-memory storage
2. **Schema Design**: Define Axion schemas for your entities
3. **Incremental Adoption**: Start with Chronicle for snapshots only
4. **Add CRDTs**: Replace coordination with conflict-free types where applicable
5. **Full Integration**: Switch to LatticeQL for querying

---

## Example: Complete Integration

```csharp
using Lattice.DB;
using Lattice.Chronicle;
using Lattice.CRDT;

// Setup storage
var storage = new FileStorageEngine();
storage.Open("game.ldb");

// Setup Chronicle
var chronicle = new ChronicleEngine(storage);
chronicle.EnsureMainTimeline();

// Game state (serialized to bytes)
var gameState = new GameState
{
    Players = new Dictionary<uint, Player>(),
    CurrentTick = 0
};

// Game loop
for (ulong tick = 0; tick < 10000; tick++)
{
    // Update simulation
    UpdateSimulation(gameState, tick);

    // Snapshot every 100 ticks
    if (tick % 100 == 0)
    {
        var stateBytes = SerializeState(gameState);
        var stateHash = ComputeHash(stateBytes);

        chronicle.CreateSnapshot(
            tick: tick,
            stateData: stateBytes,
            stateHash: stateHash
        );
    }
}

// Time-travel debugging
var buggyTick = 5234;
var travel = chronicle.TravelTo(buggyTick);
if (travel.Success)
{
    Console.WriteLine($"Traveled to tick {travel.Snapshot.Tick}");
    Console.WriteLine($"Need to replay {travel.TicksReplayed} ticks");

    // Restore and investigate
    var restoredState = DeserializeState(travel.StateData);
    DebugGameState(restoredState);
}

// Create alternate timeline
var branchPoint = chronicle.FindLatestSnapshotBefore(1, tick: 3000);
if (branchPoint != null)
{
    var branch = chronicle.Branch(branchPoint.Id, new BranchOptions
    {
        Name = "Alternate ending",
        SwitchToNewTimeline = true
    });

    // Continue simulation in alternate timeline
    // Original timeline unchanged
}

// Cleanup
chronicle.Flush();
storage.Close();
```

---

## Future Roadmap

### Short-Term (Q1 2026)
- âœ… Complete Lattice.QL query executor
- âœ… Finish Lattice.ORM Active Record implementation
- âœ… Stabilize replication protocol

### Medium-Term (Q2 2026)
- ðŸ“‹ Add Lattice.Search full-text indexing
- ðŸ“‹ Implement query optimizer
- ðŸ“‹ Add PostgreSQL compatibility layer

### Long-Term (2026+)
- ðŸ“‹ Distributed query execution
- ðŸ“‹ Sharding support for horizontal scaling
- ðŸ“‹ SQL compatibility layer

---

## Related Documents

- [Chronicle Time-Travel](./chronicle.md) - Deep dive into temporal features
- [Axion Schemas](./axion.md) - Schema language specification
- [Executive Overview](../overview/executive.md) - Platform overview

---

**Document Version:** 1.0.0
**Status:** Complete
**Next Review:** 2026-02-01
